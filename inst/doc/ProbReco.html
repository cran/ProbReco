<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Anastasios Panagiotelis" />

<meta name="date" content="2020-08-11" />

<title>Probabilistic Forecast Reconciliation via energy score optimisation.</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />




</head>

<body>




<h1 class="title toc-ignore">Probabilistic Forecast Reconciliation via energy score optimisation.</h1>
<h4 class="author">Anastasios Panagiotelis</h4>
<h4 class="date">2020-08-11</h4>



<div id="background" class="section level2">
<h2>Background</h2>
<p>The <code>ProbReco</code> package carries out probabilistic forecast reconciliation via score optimisation. This vignette describes how to set up the inputs to the main functions <code>inscoreopt()</code> and <code>scoreopt()</code> which find reconciliation weights using Stochastic Gradient Descent.</p>
<div id="probabilistic-forecast-reconciliation" class="section level3">
<h3>Probabilistic Forecast Reconciliation</h3>
<p>For a full treatment of probabilistic forecast reconciliation see <span class="citation">(Panagiotelis et al. 2020)</span>. Let <span class="math inline">\(\boldsymbol{y}_t\)</span> be a <span class="math inline">\(n\)</span>-vector observed at time <span class="math inline">\(t\)</span> that is known to belong to an <span class="math inline">\(m\)</span>-dimensional subspace of <span class="math inline">\(\mathbb{R}^n\)</span> denoted <span class="math inline">\(\mathfrak{s}\)</span> with <span class="math inline">\(m&lt;n\)</span>. Suppose that a <em>base</em> probabilistic forecast for <span class="math inline">\(\boldsymbol{y}_{t+h}\)</span> at time <span class="math inline">\(t\)</span> is defined as</p>
<p><span class="math display">\[\hat{\nu}_{t+h|t}(\mathcal{A})=\textit{Pr}(\boldsymbol{y}_t\in\mathcal{A})\,,\]</span></p>
<p>where <span class="math inline">\(\mathcal{A}\)</span> is some region of <span class="math inline">\(\mathbb{R}^n\)</span> (more precisely a member of the usual Borel <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(\mathbb{R}^n\)</span>). A <em>reconciled</em> probabilistic forecast is a probability measure <span class="math inline">\(\tilde{\nu}_{t+h|t}\)</span> with the property</p>
<p><span class="math display">\[\tilde{\nu}_{t+h|t}(\psi(\mathcal{A}))=\hat{\nu}_{t+h|t}(\mathcal{A})\,,\]</span></p>
<p>where <span class="math inline">\(\psi:\mathbb{R}^n\rightarrow\mathfrak{s}\)</span> is a mapping and <span class="math inline">\(\psi({\mathcal{A}})\)</span> is the image of <span class="math inline">\(\mathcal{A}\)</span> under <span class="math inline">\(\psi\)</span>. In this package we consider linear transformations for <span class="math inline">\(\psi\)</span></p>
<p><span class="math display">\[
\tilde{\boldsymbol{y}}_{t+h|t}=\psi(\hat{\boldsymbol{y}}_{t+h|t})=\boldsymbol{S}(\boldsymbol{d}+\boldsymbol{G}\hat{\boldsymbol{y}}_{t+h|t})\,,
\]</span> where <span class="math inline">\(\boldsymbol{S}\)</span> is an <span class="math inline">\(n\times m\)</span> matrix whose columns span <span class="math inline">\(\mathfrak{s}\)</span>. If <span class="math inline">\(\hat{\boldsymbol{y}}_{t+h|t}\)</span> is sampled from the base forecast then <span class="math inline">\(\tilde{\boldsymbol{y}}_{t+h|t}\)</span> will be sampled from the reconciled forecast. The objective of probabilistic forecast reconciliation is to find values of <span class="math inline">\(\boldsymbol{G}\)</span> and <span class="math inline">\(\boldsymbol{d}\)</span> that are optimal.</p>
</div>
<div id="scoring-rules" class="section level3">
<h3>Scoring Rules</h3>
<p>Scoring rules are used to measure the quality of probabilistic forecasts. The default loss function used by the package is the total energy score given by</p>
<p><span class="math display">\[L=\sum\limits_{t\in\mathcal{T}}\hat{K}_{t+h}\]</span></p>
<p>where <span class="math inline">\(\mathcal{T}\)</span> is a training set and <span class="math inline">\(K_{t+h}\)</span> is an estimate for energy score given by</p>
<p><span class="math display">\[\hat{K}_{t+h}=Q^{-1}\left(\sum\limits_{q=1}^Q\left|\left|\boldsymbol{y}_{t+h}-\boldsymbol{S}\left(\boldsymbol{d}+\boldsymbol{G}\hat{\boldsymbol{y}}^{[q]}_{t+h|t}\right)\right|\right|^\alpha-\frac{1}{2}\sum\limits_{q=1}^Q\left|\left|\boldsymbol{SG}\left(\hat{\boldsymbol{y}}^{[q]}_{t+h|t}-\hat{\boldsymbol{y}}^{[q]*}_{t+h|t}\right)\right|\right|^\alpha\right)\,,\]</span></p>
<p>where <span class="math inline">\(\hat{\boldsymbol{y}}^{[1]}_{t+h|t},\ldots,\hat{\boldsymbol{y}}^{[Q]}_{t+h|t}\)</span> and <span class="math inline">\(\hat{\boldsymbol{y}}^{[1]*}_{t+h|t},\ldots,\hat{\boldsymbol{y}}^{[Q]*}_{t+h|t}\)</span> are independent copies drawn from the base forecast distribution, <span class="math inline">\(||.||\)</span> is the <span class="math inline">\(L_2\)</span> norm and <span class="math inline">\(\alpha\in(0,2]\)</span> with <span class="math inline">\(\alpha=1\)</span> by default. Note that this representation is a negatively oriented energy score, i.e. smaller values of the score indicate more accurate forecasts. For more on scoring rules see <span class="citation">(Gneiting and Raftery 2007)</span>.</p>
<p>The variogram score <span class="citation">(Scheuerer and Hamill 2015)</span> is also implemented in the package and is given by</p>
<p><span class="math display">\[\hat{K}_{t+h}=\sum\limits_{i=1}^n\sum\limits_{j=1}^n\left(\left|\left|y_{i,t+h}-y_{j,t+h}\right|\right|^\alpha-Q^{-1}\sum\limits_{q=1}^Q\left|\left|\tilde{y}^{[q]}_{i,t+h|t}-\tilde{y}^{[q]*}_{j,t+h|t}\right|\right|^\alpha\right)\,,\]</span> where <span class="math inline">\(\tilde{\boldsymbol{y}}^{[q]}_{t+h|t}=\boldsymbol{S}(\boldsymbol{d}+\boldsymbol{G}\hat{\boldsymbol{y}}^{[q]}_{t+h|t})\)</span>, <span class="math inline">\(\tilde{\boldsymbol{y}}^{[q]*}_{t+h|t}=\boldsymbol{S}(\boldsymbol{d}+\boldsymbol{G}\hat{\boldsymbol{y}}^{[q]*}_{t+h|t})\)</span> and <span class="math inline">\(\alpha=1\)</span> by default (but can be changed).</p>
</div>
<div id="optimisation" class="section level3">
<h3>Optimisation</h3>
<p>A challenging aspect of optimising the loss function is its stochastic nature. The technique used to maximise the loss function is <em>Stochastic Gradient Descent</em>. The gradients with respect to <span class="math inline">\(\boldsymbol{G}\)</span> and <span class="math inline">\(\boldsymbol{d}\)</span> are found using algorithmic differentiation which is implemented using the Stan Math C++ header only library <span class="citation">(see Carpenter et al. 2015)</span>. The learning rates for each update are determined using the Adam method <span class="citation">(see Kingma and Ba 2014)</span>.</p>
</div>
</div>
<div id="using-the-inscoreopt-function" class="section level2">
<h2>Using the <code>inscoreopt()</code> function</h2>
<p>The more straightforward function to use in the package is <code>inscoreopt()</code>. This only requires the data and predicted values. The probabilistic forecasts are not true forecasts in the sense that they are obtained using in sample information.</p>
<div id="the-s-matrix" class="section level3">
<h3>The S matrix</h3>
<p>Consider a 3-variable hierarchy where <span class="math inline">\(y_{1,t}=y_{2,t}+y_{3,t}\)</span>. An <span class="math inline">\(\boldsymbol{S}\)</span> matrix for this hierarchy is</p>
<p><span class="math display">\[\boldsymbol{S}=\begin{pmatrix}1&amp;1\\1&amp;0\\0&amp;1\end{pmatrix}\]</span></p>
<p>which we define in R by</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">S&lt;-<span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>),<span class="dv">3</span>,<span class="dv">2</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>)
S
<span class="co">#&gt;      [,1] [,2]</span>
<span class="co">#&gt; [1,]    1    1</span>
<span class="co">#&gt; [2,]    1    0</span>
<span class="co">#&gt; [3,]    0    1</span></code></pre></div>
</div>
<div id="the-data" class="section level3">
<h3>The data</h3>
<p>Suppose the data are given by</p>
<p><span class="math display">\[\begin{pmatrix}y_{2,t}\\y_{3,t}\end{pmatrix}\sim N\left(\begin{pmatrix}1\\1\end{pmatrix},\begin{pmatrix}1&amp;0\\0&amp;1\end{pmatrix}\right)\,,\]</span></p>
<p>to demonstrate the functions, ten observations of data from the full hierarchy can be simulated by</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">y&lt;-<span class="kw">matrix</span>(<span class="ot">NA</span>,<span class="dv">3</span>,<span class="dv">10</span>) <span class="co">#preallocate matrix</span>
<span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">10</span>){
  y[,t]&lt;-S<span class="op">%*%</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>)<span class="op">+</span><span class="kw">rnorm</span>(<span class="dv">2</span>))
}</code></pre></div>
<p>Naturally, in real applications the data will not need to be simulated.</p>
<p>For demonstration purposes, suppose the predicted values are simply randomly generated from a uniform distribution (in a real applications these will come from a model). The argument <code>yhat</code> must be a matrix of the same size as <code>y</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">yhat&lt;-<span class="kw">matrix</span>(<span class="kw">runif</span>(<span class="dv">30</span>),<span class="dv">3</span>,<span class="dv">10</span>)</code></pre></div>
<p>The reconciliation weights can be trained via</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ProbReco)
out&lt;-<span class="kw">inscoreopt</span>(<span class="dt">y=</span>y,<span class="dt">yhat=</span>yhat,<span class="dt">S=</span>S)
out<span class="op">$</span>d
<span class="co">#&gt; [1] 0.2890895 0.2739345</span>
out<span class="op">$</span>G
<span class="co">#&gt;           [,1]       [,2]        [,3]</span>
<span class="co">#&gt; [1,] 0.5204758  0.7639945 -0.02491508</span>
<span class="co">#&gt; [2,] 0.4550564 -0.1715359  0.74337060</span></code></pre></div>
<p>Different assumptions can be made about Gaussianity and dependence in the base forecasts using the arguments <code>basedep</code> and <code>basedist</code></p>
</div>
</div>
<div id="setting-up-function-inputs-for-scoreopt" class="section level2">
<h2>Setting up function inputs for <code>scoreopt()</code></h2>
<p>This section describes how to set up the inputs for the <code>scoreopt()</code> function. These are more easily created by the <code>purrr</code> package which can be loaded using:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(purrr)</code></pre></div>
<div id="the-data-argument" class="section level3">
<h3>The <code>data</code> argument</h3>
<p>In general, rather than using in-sample predictions, a rolling window can be set up where probabilistic forecasts and realisations are both used to train reconciliation weights. The <code>data</code> argument is a list where each list element is an <span class="math inline">\(n\)</span>-vector corresponding to a realisation of the data. Each element of the list corresponds to a training observation. Assuming the same DGP as the previous example, this can be constructed as follows</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data&lt;-<span class="kw">map</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>,<span class="cf">function</span>(i){S<span class="op">%*%</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>)<span class="op">+</span><span class="kw">rnorm</span>(<span class="dv">2</span>))})
data[[<span class="dv">1</span>]]
<span class="co">#&gt;          [,1]</span>
<span class="co">#&gt; [1,] 3.020937</span>
<span class="co">#&gt; [2,] 1.786201</span>
<span class="co">#&gt; [3,] 1.234737</span>
data[[<span class="dv">5</span>]]
<span class="co">#&gt;          [,1]</span>
<span class="co">#&gt; [1,] 2.501348</span>
<span class="co">#&gt; [2,] 1.270163</span>
<span class="co">#&gt; [3,] 1.231185</span></code></pre></div>
<p>In practice, an actual dataset will need to be converted into this form. This form of storing data is unconvential but allows for great flexibility in the way base probabilistic forecasts can be defined.</p>
</div>
<div id="the-prob-argument" class="section level3">
<h3>The <code>prob</code> argument</h3>
<p>The base probabilistic forecast in general will vary for each period of the training sample. This information is also stored in a list. Each list element corresponds to a training observation. The list elements themselves are functions that simulate from the base probabilistic distribution.</p>
<p>Suppose that the base probabilistic forecast is to simulate from a trivariate standard normal <span class="math inline">\(N(\boldsymbol{0}_{3\times 1},\boldsymbol{I}_{3\times 3})\)</span> for each training observation (in practice the probabilistic forecast will vary over the training observations). First define a function that simulates 50 iterates from <span class="math inline">\(N(\boldsymbol{0}_{3\times 1},\boldsymbol{I}_{3\times 3})\)</span> and stores these in a matrix. In practice a value larger than 50 should be used to estimate the energy score. A list of these functions can be created using the <code>map()</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Function</span>
f&lt;-<span class="cf">function</span>(){<span class="kw">matrix</span>(<span class="kw">rnorm</span>(<span class="dv">50</span><span class="op">*</span><span class="dv">3</span>),<span class="dv">3</span>,<span class="dv">50</span>)}
prob&lt;-<span class="kw">map</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>,<span class="cf">function</span>(i){f})
prob[[<span class="dv">1</span>]]
<span class="co">#&gt; function(){matrix(rnorm(50*3),3,50)}</span>
prob[[<span class="dv">5</span>]]
<span class="co">#&gt; function(){matrix(rnorm(50*3),3,50)}</span></code></pre></div>
</div>
<div id="the-gvec-and-ginit-argument" class="section level3">
<h3>The <code>Gvec</code> and <code>Ginit</code> argument</h3>
<p>The reconciliation parameters enter functions as a single argument. The first <span class="math inline">\(m\)</span> elements are the elements of <span class="math inline">\(\boldsymbol{d}\)</span>. The remaining elements are the elements of <span class="math inline">\(\boldsymbol{G}\)</span> vectorised (in column-major ordering). A random initial value can be simulated as</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Gvec&lt;-<span class="kw">runif</span>(<span class="dv">8</span>)
Gvec
<span class="co">#&gt; [1] 0.84437123 0.45541695 0.59426441 0.06415706 0.32560712 0.49533097 0.41080253</span>
<span class="co">#&gt; [8] 0.13278460</span></code></pre></div>
</div>
<div id="checking-inputs-with-checkinputs" class="section level3">
<h3>Checking inputs with <code>checkinputs</code></h3>
<p>To check that all inputs are correctly specified use the <code>checkinputs()</code> function</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">checkinputs</span>(data,prob,S,Gvec)</code></pre></div>
<p>An error will be thrown if an input is incorrectly set up.</p>
</div>
</div>
<div id="the-total_score-and-scoreopt-functions" class="section level2">
<h2>The <code>total_score</code> and <code>scoreopt</code> functions</h2>
<p>The function <code>total_score()</code> provides an estimate of the total score and its gradient. The gradient is evaluated by algorithmic differentiation.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">out&lt;-<span class="kw">total_score</span>(data,prob,S,Gvec)
out<span class="op">$</span>value
<span class="co">#&gt; [1] 20.21764</span>
out<span class="op">$</span>grad
<span class="co">#&gt; [1] -3.7151235 -2.1254724 -1.7135674 -0.1695672 -0.3625651 -2.0611004 -1.1712909</span>
<span class="co">#&gt; [8] -0.8725126</span></code></pre></div>
<p>Since the loss function is stochastic, these values will change each time the function is run.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">out2&lt;-<span class="kw">total_score</span>(data,prob,S,Gvec)
out<span class="op">$</span>value
<span class="co">#&gt; [1] 20.21764</span>
out2<span class="op">$</span>value
<span class="co">#&gt; [1] 19.99923</span>
out<span class="op">$</span>grad
<span class="co">#&gt; [1] -3.7151235 -2.1254724 -1.7135674 -0.1695672 -0.3625651 -2.0611004 -1.1712909</span>
<span class="co">#&gt; [8] -0.8725126</span>
out2<span class="op">$</span>grad
<span class="co">#&gt; [1] -4.1454552 -2.4424070 -1.9166395 -0.7954665 -1.0984027 -2.2855283 -0.8056046</span>
<span class="co">#&gt; [8] -0.4656124</span></code></pre></div>
<p>The function <code>scoreopt()</code> maximises the loss function using stochastic gradient descent.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">out&lt;-<span class="kw">scoreopt</span>(data,prob,S)</code></pre></div>
<p>The output includes <span class="math inline">\(\boldsymbol{d}\)</span> and <span class="math inline">\(\boldsymbol{G}\)</span> which is converted back to a matrix using column-major ordering. The converged value of the loss function is also provided.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">out<span class="op">$</span>d
<span class="co">#&gt; [1] 0.4430438 0.4169748</span>
out<span class="op">$</span>G
<span class="co">#&gt;           [,1]        [,2]       [,3]</span>
<span class="co">#&gt; [1,] 0.6733619  1.04035368 -0.3174013</span>
<span class="co">#&gt; [2,] 0.6452485 -0.02940679  0.9918338</span>
out<span class="op">$</span>val
<span class="co">#&gt; [1] 20.1352</span></code></pre></div>
<p>Since everything is Gaussian, and the true mean of the base forecasts is <span class="math inline">\(\boldsymbol{0}\)</span>, the mean of the reconciled distribution is given by <span class="math inline">\(\boldsymbol{S}\boldsymbol{a}\)</span>. The variance covariance matrix is given by <span class="math inline">\(\boldsymbol{S}\boldsymbol{G}\boldsymbol{I}\boldsymbol{G}'\boldsymbol{S}'\)</span>. The mean</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">S<span class="op">%*%</span>out<span class="op">$</span>d
<span class="co">#&gt;           [,1]</span>
<span class="co">#&gt; [1,] 0.8600187</span>
<span class="co">#&gt; [2,] 0.4430438</span>
<span class="co">#&gt; [3,] 0.4169748</span></code></pre></div>
<p>is close to the true mean of <span class="math inline">\((2,1,1)'\)</span> (keeping in mind that the sample size is small). The variance covariance matrix is</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">S<span class="op">%*%</span>out<span class="op">$</span>G<span class="op">%*%</span><span class="kw">t</span>(out<span class="op">$</span>G)<span class="op">%*%</span><span class="kw">t</span>(S)
<span class="co">#&gt;          [,1]       [,2]       [,3]</span>
<span class="co">#&gt; [1,] 3.215606 1.72557850 1.49002758</span>
<span class="co">#&gt; [2,] 1.725578 1.63649558 0.08908292</span>
<span class="co">#&gt; [3,] 1.490028 0.08908292 1.40094467</span></code></pre></div>
<p>which is close to the true variance covariance matrix</p>
<p><span class="math display">\[\begin{pmatrix}2&amp;1&amp;1\\1&amp;1&amp;0\\1&amp;0&amp;1\end{pmatrix}\]</span></p>
<p>These values will be even closer if more training observations are used and more iterates are drawn from the probabilistic forecasts to estimate the score.</p>
</div>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references">
<div id="ref-stan">
<p>Carpenter, Bob, Matthew D. Hoffman, Marcus Brubaker, Daniel Lee, Peter Li, and Michael Betancourt. 2015. “The Stan Math Library: Reverse-Mode Automatic Differentiation in C++.” <em>arXiv Preprint</em>. <a href="https://arxiv.org/abs/1509.07164" class="uri">https://arxiv.org/abs/1509.07164</a>.</p>
</div>
<div id="ref-scores">
<p>Gneiting, Tilmann, and Adrian E Raftery. 2007. “Strictly Proper Scoring Rules, Prediction, and Estimation.” <em>Journal of the American Statistical Association</em> 102 (477). Taylor &amp; Francis: 359–78. <a href="https://doi.org/10.1198/016214506000001437" class="uri">https://doi.org/10.1198/016214506000001437</a>.</p>
</div>
<div id="ref-adam">
<p>Kingma, Diederik P, and Jimmy Ba. 2014. “Adam: A Method for Stochastic Optimization.” <em>arXiv Preprint</em>. <a href="https://arxiv.org/abs/1412.6980" class="uri">https://arxiv.org/abs/1412.6980</a>.</p>
</div>
<div id="ref-wp">
<p>Panagiotelis, Anastasios, Puwasala Gamakumara, George Athanasopoulos, and Rob Hyndman. 2020. “Probabilistic Forecast Reconciliation: Propoerties, Evaluation and Score Optimisation.” <em>Monash EBS Working Paper 26/20</em>. <a href="https://www.monash.edu/business/ebs/research/publications/ebs/wp26-2020.pdf" class="uri">https://www.monash.edu/business/ebs/research/publications/ebs/wp26-2020.pdf</a>.</p>
</div>
<div id="ref-variogram">
<p>Scheuerer, Michael, and Thomas M. Hamill. 2015. “Variogram-Based Proper Scoring Rules for Probabilistic Forecasts of Multivariate Quantities.” <em>Monthly Weather Review</em> 143 (4): 1321–34. <a href="https://doi.org/10.1175/MWR-D-14-00269.1" class="uri">https://doi.org/10.1175/MWR-D-14-00269.1</a>.</p>
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
